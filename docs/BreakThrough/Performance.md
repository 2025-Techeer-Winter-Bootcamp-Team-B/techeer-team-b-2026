# ğŸš€ ì„±ëŠ¥ ìµœì í™” BreakThrough

ì„±ëŠ¥ ê´€ë ¨ ë¬¸ì œ í•´ê²° ë° ìµœì í™” ì‚¬ë¡€ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## 1. ê²€ìƒ‰ ì†ë„ ìµœì í™”

### ë¬¸ì œ ìƒí™©
- LIKE '%keyword%' ê²€ìƒ‰ì´ **2-3ì´ˆ** ì†Œìš”
- 10ë§Œ ê±´ ì´ìƒì˜ ì•„íŒŒíŠ¸ ë°ì´í„°ì—ì„œ ì „ì²´ í…Œì´ë¸” ìŠ¤ìº” ë°œìƒ
- ì¸ë±ìŠ¤ë¥¼ í™œìš©í•˜ì§€ ëª»í•¨

### í•´ê²° ë°©ë²•
2ë‹¨ê³„ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ë„ì…:

```python
# 1ë‹¨ê³„: PREFIX ê²€ìƒ‰ (ì¸ë±ìŠ¤ í™œìš©)
stmt = select(Apartment).where(
    func.lower(Apartment.apt_name).like(f"{query.lower()}%")
)

# 2ë‹¨ê³„: pg_trgm ìœ ì‚¬ë„ ê²€ìƒ‰ (ê²°ê³¼ ë¶€ì¡± ì‹œ)
stmt = select(Apartment).where(
    func.similarity(Apartment.apt_name, query) > 0.3
).order_by(func.similarity(Apartment.apt_name, query).desc())
```

### ê°œì„  ê²°ê³¼
| ì§€í‘œ | ê°œì„  ì „ | ê°œì„  í›„ |
|------|---------|---------|
| ì‘ë‹µ ì‹œê°„ | 2-3ì´ˆ | **50-100ms** |
| ê°œì„ ìœ¨ | - | **95%â†“** |

---

## 2. Cold Start ë¬¸ì œ í•´ê²°

### ë¬¸ì œ ìƒí™©
- ì„œë²„ ì¬ì‹œì‘ í›„ ì²« ëŒ€ì‹œë³´ë“œ ìš”ì²­ì´ **3-5ì´ˆ** ì†Œìš”
- ë³µì¡í•œ í†µê³„ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•´ì•¼ í•¨
- ì‚¬ìš©ì ê²½í—˜ ì €í•˜

### í•´ê²° ë°©ë²•
ì„œë²„ ì‹œì‘ ì‹œ ìºì‹œ ì˜ˆì—´:

```python
@app.on_event("startup")
async def startup_event():
    await get_redis_client()
    # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ìœ¼ë¡œ ì„œë²„ ì‹œì‘ ë¸”ë¡œí‚¹ ì—†ìŒ
    asyncio.create_task(preload_home_cache())

async def preload_home_cache():
    PRELOAD_TTL = 43200  # 12ì‹œê°„
    
    tasks = [
        ("dashboard/summary", {"transaction_type": "sale"}),
        ("dashboard/summary", {"transaction_type": "jeonse"}),
        ("dashboard/rankings", {"transaction_type": "sale"}),
        ("dashboard/rankings", {"transaction_type": "jeonse"}),
    ]
    
    for endpoint, params in tasks:
        data = await fetch_data(endpoint, params)
        await cache_data(endpoint, params, data, ttl=PRELOAD_TTL)
```

### ê°œì„  ê²°ê³¼
| ì§€í‘œ | ê°œì„  ì „ | ê°œì„  í›„ |
|------|---------|---------|
| ì²« ìš”ì²­ ì‘ë‹µ | 3-5ì´ˆ | **50-100ms** |
| ìºì‹œ ë¯¸ìŠ¤ | 100% | **0%** (ì˜ˆì—´ í›„) |

---

## 3. JSON ì§ë ¬í™” ìµœì í™”

### ë¬¸ì œ ìƒí™©
- ëŒ€ì‹œë³´ë“œ APIê°€ ìˆ˜ë°± ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ ë°˜í™˜
- í‘œì¤€ json ëª¨ë“ˆë¡œ ì§ë ¬í™” ì‹œ **45ms** ì†Œìš”
- API ì‘ë‹µ ìƒì„± ì‹œê°„ì´ ì „ì²´ ì‘ë‹µì˜ ìƒë‹¹ ë¶€ë¶„ ì°¨ì§€

### í•´ê²° ë°©ë²•
orjson ì ìš©:

```python
# app/main.py
from fastapi.responses import ORJSONResponse

app = FastAPI(
    default_response_class=ORJSONResponse,  # ëª¨ë“  ì‘ë‹µì— ì ìš©
)
```

### ê°œì„  ê²°ê³¼
| ì§€í‘œ | ê°œì„  ì „ (json) | ê°œì„  í›„ (orjson) |
|------|---------------|-----------------|
| ì§ë ¬í™” ì‹œê°„ | 45ms | **9ms** |
| ê°œì„ ìœ¨ | - | **80%â†“** |

---

## 4. Connection Pool ìµœì í™”

### ë¬¸ì œ ìƒí™©
- ë™ì‹œ ìš”ì²­ì´ ë§ì•„ì§€ë©´ "connection pool exhausted" ì—ëŸ¬
- ê¸°ë³¸ ì„¤ì • pool_size=5ë¡œ ë¶€ì¡±

### í•´ê²° ë°©ë²•

```python
engine = create_async_engine(
    DATABASE_URL,
    pool_size=20,          # 5 â†’ 20
    max_overflow=40,       # 10 â†’ 40
    pool_timeout=30,
    pool_recycle=1800,     # 30ë¶„ë§ˆë‹¤ ì¬ì‚¬ìš©
    pool_pre_ping=True,    # ì—°ê²° ìœ íš¨ì„± ì‚¬ì „ í™•ì¸
)
```

### ê°œì„  ê²°ê³¼
| ì§€í‘œ | ê°œì„  ì „ | ê°œì„  í›„ |
|------|---------|---------|
| ë™ì‹œ ì—°ê²° ìˆ˜ | 50 | **200+** |
| Connection ì—ëŸ¬ | ë°œìƒ | **ì—†ìŒ** |

---

## 5. í†µê³„ ìºì‹œ ì „ëµ ê°œì„ 

### ë¬¸ì œ ìƒí™©
- í†µê³„ APIì˜ í•„í„° ì¡°í•©ì´ ë‹¤ì–‘í•¨ (ì§€ì—­, ê±°ë˜ ìœ í˜•, ê¸°ê°„ ë“±)
- ë‹¨ìˆœ ìºì‹œ í‚¤ë¡œëŠ” ëª¨ë“  ì¡°í•© ì»¤ë²„ ë¶ˆê°€
- ìºì‹œ ë¯¸ìŠ¤ìœ¨ ë†’ìŒ

### í•´ê²° ë°©ë²•
í•´ì‹œ ê¸°ë°˜ ìºì‹œ í‚¤ ìƒì„±:

```python
def generate_hash_key(*args, **kwargs) -> str:
    """ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ í•´ì‹œí•˜ì—¬ ê³ ì • ê¸¸ì´ í‚¤ ìƒì„±"""
    key_data = orjson.dumps({
        "args": args,
        "kwargs": sorted(kwargs.items())
    })
    return f"realestate:{hashlib.md5(key_data).hexdigest()}"

# ì‚¬ìš© ì˜ˆ
cache_key = generate_hash_key(
    "statistics", "rvol",
    region_type="ì „êµ­",
    transaction_type="sale",
    period_months=3
)
# â†’ "realestate:a1b2c3d4..."
```

### ê°œì„  ê²°ê³¼
| ì§€í‘œ | ê°œì„  ì „ | ê°œì„  í›„ |
|------|---------|---------|
| ìºì‹œ íˆíŠ¸ìœ¨ | 40% | **80%+** |
| ìºì‹œ í‚¤ ì¶©ëŒ | ë°œìƒ | **ì—†ìŒ** |

---

## 6. N+1 ë¬¸ì œ í•´ê²°

### ë¬¸ì œ ìƒí™©
- ì•„íŒŒíŠ¸ ëª©ë¡ ì¡°íšŒ ì‹œ ê° ì•„íŒŒíŠ¸ì˜ ìƒì„¸ ì •ë³´ë¥¼ ê°œë³„ ì¿¼ë¦¬ë¡œ ì¡°íšŒ
- 100ê°œ ì•„íŒŒíŠ¸ = 101ê°œ ì¿¼ë¦¬ (1 + 100)

### í•´ê²° ë°©ë²•

```python
# Before: N+1 ë¬¸ì œ
for apt_id in apt_ids:
    detail = await get_apart_detail(db, apt_id)

# After: ë°°ì¹˜ ì¡°íšŒ
stmt = (
    select(Apartment)
    .options(selectinload(Apartment.detail))
    .where(Apartment.apt_id.in_(apt_ids))
)
apartments = await db.execute(stmt)
```

### ê°œì„  ê²°ê³¼
| ì§€í‘œ | ê°œì„  ì „ | ê°œì„  í›„ |
|------|---------|---------|
| ì¿¼ë¦¬ ìˆ˜ | 101ê°œ | **2ê°œ** |
| ì‘ë‹µ ì‹œê°„ | 500ms | **50ms** |

---

## 7. ì„œë¸Œì¿¼ë¦¬ â†’ JOIN ì „í™˜

### ë¬¸ì œ ìƒí™©
- ì„œë¸Œì¿¼ë¦¬ ë‚¨ìš©ìœ¼ë¡œ ì¿¼ë¦¬ ì„±ëŠ¥ ì €í•˜
- ë³µì¡í•œ ì‹¤í–‰ ê³„íšìœ¼ë¡œ ìµœì í™” ì–´ë ¤ì›€

### í•´ê²° ë°©ë²•

```python
# Before: ì„œë¸Œì¿¼ë¦¬
stmt = select(Apartment).where(
    Apartment.apt_id.in_(
        select(Sale.apt_id)
        .where(Sale.contract_date >= date_from)
    )
)

# After: JOIN
stmt = (
    select(Apartment)
    .join(Sale, Apartment.apt_id == Sale.apt_id)
    .where(Sale.contract_date >= date_from)
    .group_by(Apartment.apt_id)
)
```

### ê°œì„  ê²°ê³¼
| ì§€í‘œ | ê°œì„  ì „ | ê°œì„  í›„ |
|------|---------|---------|
| ì¿¼ë¦¬ ì‹œê°„ | 200ms | **100ms** |
| ê°œì„ ìœ¨ | - | **50%â†“** |

---

## 8. ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë„ì…

### ë¬¸ì œ ìƒí™©
- ì–´ë–¤ APIê°€ ëŠë¦°ì§€ íŒŒì•… ë¶ˆê°€
- ì„±ëŠ¥ ë³‘ëª© ì§€ì  ì‹ë³„ ì–´ë ¤ì›€
- ì¥ì•  ë°œìƒ ì‹œ ì›ì¸ íŒŒì•… ì§€ì—°

### í•´ê²° ë°©ë²•
Prometheus + Grafana ë„ì…:

```python
# app/main.py
from prometheus_fastapi_instrumentator import Instrumentator

# ë©”íŠ¸ë¦­ ìë™ ìˆ˜ì§‘
Instrumentator().instrument(app).expose(app)
```

ìˆ˜ì§‘ ë©”íŠ¸ë¦­:
- HTTP ìš”ì²­ ìˆ˜ (RPS)
- ì‘ë‹µ ì‹œê°„ (p50, p95, p99)
- ì—ëŸ¬ìœ¨ (5xx / ì „ì²´)
- í™œì„± ì—°ê²° ìˆ˜

### ê°œì„  ê²°ê³¼
| ì§€í‘œ | ê°œì„  ì „ | ê°œì„  í›„ |
|------|---------|---------|
| ëª¨ë‹ˆí„°ë§ | ì—†ìŒ | **ì‹¤ì‹œê°„** |
| ë³‘ëª© ì‹ë³„ | ìˆ˜ë™ | **ìë™** |

---

## 9. ëŠë¦° ìš”ì²­ ê°ì§€ ë¯¸ë“¤ì›¨ì–´

### ë¬¸ì œ ìƒí™©
- 5ì´ˆ ì´ìƒ ê±¸ë¦¬ëŠ” ìš”ì²­ ê°ì§€ ë¶ˆê°€
- íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ë¯¸ë¹„

### í•´ê²° ë°©ë²•

```python
# app/core/middleware.py
class PerformanceMiddleware:
    async def __call__(self, request, call_next):
        start = time.time()
        response = await call_next(request)
        duration = time.time() - start
        
        # 5ì´ˆ ì´ìƒ ê²½ê³ 
        if duration > 5:
            logger.warning(f"ëŠë¦° ìš”ì²­: {request.url} ({duration:.2f}s)")
        
        # 60ì´ˆ ì´ˆê³¼ íƒ€ì„ì•„ì›ƒ
        if duration > 60:
            return JSONResponse(
                status_code=504,
                content={"error": "Request timeout"}
            )
        
        response.headers["X-Response-Time"] = f"{duration:.3f}s"
        return response
```

### ê°œì„  ê²°ê³¼
| ì§€í‘œ | ê°œì„  ì „ | ê°œì„  í›„ |
|------|---------|---------|
| ëŠë¦° ìš”ì²­ ê°ì§€ | ë¶ˆê°€ | **ìë™ ê²½ê³ ** |
| íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ | ì—†ìŒ | **60ì´ˆ ì œí•œ** |

---

## 10. ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬

### ë¬¸ì œ ìƒí™©
- ì—¬ëŸ¬ í†µê³„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ê³„ì‚°
- ì „ì²´ ì‘ë‹µ ì‹œê°„ ì¦ê°€

### í•´ê²° ë°©ë²•

```python
import asyncio

async def calculate_all_statistics():
    # ë³‘ë ¬ ì‹¤í–‰
    results = await asyncio.gather(
        calculate_rvol(),
        calculate_quadrant(),
        calculate_hpi(),
        calculate_transaction_volume(),
    )
    return {
        "rvol": results[0],
        "quadrant": results[1],
        "hpi": results[2],
        "volume": results[3],
    }
```

### ê°œì„  ê²°ê³¼
| ì§€í‘œ | ê°œì„  ì „ (ìˆœì°¨) | ê°œì„  í›„ (ë³‘ë ¬) |
|------|---------------|---------------|
| ì´ ì‹œê°„ | 4ì´ˆ (1+1+1+1) | **1.2ì´ˆ** (ìµœëŒ€ê°’) |
| ê°œì„ ìœ¨ | - | **70%â†“** |

---

## 11. ìºì‹œ ë¬´íš¨í™” ì „ëµ

### ë¬¸ì œ ìƒí™©
- ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œ ê´€ë ¨ ìºì‹œ ë¬´íš¨í™” ë¶ˆì™„ì „
- ì˜¤ë˜ëœ ë°ì´í„° ì œê³µ ê°€ëŠ¥

### í•´ê²° ë°©ë²•
íŒ¨í„´ ë§¤ì¹­ ê¸°ë°˜ ì„ íƒì  ë¬´íš¨í™”:

```python
async def invalidate_statistics_cache(
    region_id: Optional[int] = None,
    transaction_type: Optional[str] = None
):
    patterns = []
    
    if region_id:
        patterns.append(f"realestate:statistics:*:region:{region_id}:*")
    if transaction_type:
        patterns.append(f"realestate:statistics:*:type:{transaction_type}:*")
    
    for pattern in patterns:
        cursor = 0
        while True:
            cursor, keys = await redis.scan(cursor, match=pattern)
            if keys:
                await redis.delete(*keys)
            if cursor == 0:
                break
```

### ê°œì„  ê²°ê³¼
| ì§€í‘œ | ê°œì„  ì „ | ê°œì„  í›„ |
|------|---------|---------|
| ë¬´íš¨í™” ì •í™•ë„ | ë¶ˆì™„ì „ | **100%** |
| ë°ì´í„° ì‹ ì„ ë„ | ë¶ˆí™•ì‹¤ | **ë³´ì¥** |

---

## 12. í†µê³„ ì‚¬ì „ ê³„ì‚° ìŠ¤ì¼€ì¤„ëŸ¬

### ë¬¸ì œ ìƒí™©
- í†µê³„ ìºì‹œ ë§Œë£Œ ì‹œ ì²« ìš”ì²­ì´ ëŠë¦¼
- ëª¨ë“  í•„í„° ì¡°í•©ì„ ë¯¸ë¦¬ ê³„ì‚°í•˜ì§€ ì•ŠìŒ

### í•´ê²° ë°©ë²•
ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ ì£¼ê¸°ì  ì‚¬ì „ ê³„ì‚°:

```python
from apscheduler.schedulers.asyncio import AsyncIOScheduler

scheduler = AsyncIOScheduler()

async def precompute_all_statistics():
    region_types = ["ì „êµ­", "ìˆ˜ë„ê¶Œ", "ì§€ë°©5ëŒ€ê´‘ì—­ì‹œ"]
    transaction_types = ["sale", "jeonse"]
    
    for region in region_types:
        for tx_type in transaction_types:
            data = await calculate_statistics(region, tx_type)
            await cache_statistics(region, tx_type, data)

# ë§¤ì¼ ìƒˆë²½ 2ì‹œ ì‹¤í–‰
scheduler.add_job(precompute_all_statistics, "cron", hour=2)
scheduler.start()
```

### ê°œì„  ê²°ê³¼
| ì§€í‘œ | ê°œì„  ì „ | ê°œì„  í›„ |
|------|---------|---------|
| ìºì‹œ ë§Œë£Œ í›„ ì²« ìš”ì²­ | 3-5ì´ˆ | **ì¦‰ì‹œ** (ì‚¬ì „ ê³„ì‚°) |
| ìºì‹œ ì»¤ë²„ë¦¬ì§€ | ë¶€ë¶„ | **ì „ì²´** |
